---
layout: post
title: 决策树
categories: 模型
tags: 机器学习
keywords: Decision Tree Classifier
description:
---
决策树是一种强大的`有监督`数据挖掘技术，它能解决的问题范围非常广，而且产生的模型`具有可解释性`，而且可以用来`筛选变量`。


step1，决策树利用一个递归过程将数据切分到越来越小的单元格中，单元格
中数据逐步得到“净化”，在这个过程中，决策树会选择出对有知道数据挖掘任务最重要的那些变量。由此可知，决策树不仅可以用来构建模型。

step2，决策树利用目标变量来确定如何划分每个输入。最后，
决策树将数据分解为不同的片段，它们是由每一步的划分规则所定义。将所有片段中对应的规则整合在一起就构成了决策树模型。

决策树算法包括特征选择、决策树生成、决策树剪枝  


决策树的特点：
- 每个节点两个走向
- 每个节点1个变量
- 变量可以重复使用



优点：  
- 易于理解和解释，人们都有能力理解决策树所表达的意义  
例如，收集专家的历史数据，用决策树可以总结出他的经验。  
例如，拿到别人的交易清单，可以模拟出这个交易员  
- 和其它模型相比，数据的预处理往往是不必要的。例如，不需要归一化
- 可以同时处理分类变量和连续变量。其它模型很多要求数据类型单一
- 白盒模型，可以轻松推出逻辑表达式
- 计算量少，大量数据可也以快速得出良好结果  

缺点：  
- 样本各类别数量不同时，结果更偏向于类别多的。
（除了朴素贝叶斯之外的大多数模型都存在这个问题）
- 过拟合
- 忽略自变量之间的相关性







## 理论推导

Quinlan在1986年提出ID3,1993年提出C4.5  
Breiman在1984年提出CART算法

C4.5算法是ID3算法的改进：
   1) 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；
   2) 在树构造过程中进行剪枝；
   3) 能够完成对连续属性的离散化处理；
   4) 能够对不完整数据进行处理。
   C4.5算法有如下优点：产生的分类规则易于理解，准确率较高。其缺点是：在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。此外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。

### 定义
决策树是由node和directed edge组成  
其中node有两种：   
- internal node表示一个特征或属性  
- leaf node 表示一个类  


决策树有一个重要性质：互斥且完备。意思是每个case都被一条路径覆盖，并且只被一条路径覆盖  

### 输入数据
给定的数据是$D=\{(x_1,y_1),(x_2,y_2),...(x_N,y_N) \}$  
其中，  
$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})$是一个样本,有n个维度  
$y_i \in {1,2,...K}$类标记  
N是样本容量  
### 模型
问题是找出$P(Y \mid X)$，X是表示特征的随机变量，Y是表示类的随机变量     
lost function是正则化极大似然函数     
遍历是一个NP完全问题，因此改用启发式方法近似求解   

### 算法

Step1：特征选择

Step2：生成。先构建根节点，选择一个最优的特征（字段），进行分类。如果分类正确的子集，构建leaf node；如果有子集分类不正确，那么构建子节点。子节点按相同的方法递归进行。

Step3：剪枝。




生成是局部选择，剪枝是全局选择  

####


---

## python实现：

### 环境准备

用Python的sklearn做模型。为了可视化输出，进行下面的配置：

1. 安装pydotplus：  
https://github.com/carlos-jenkins/pydotplus
2. 安装graphviz（好像不必要）    
conda install graphviz

3. 安装软件graphviz，官网：  
http://www.graphviz.org/Download.php

4. 加入环境变量：
```py
import os
os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'
```
