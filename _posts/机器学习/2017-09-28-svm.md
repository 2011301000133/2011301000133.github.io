---
layout: post
title: 【SVM】理论与实现
categories: 算法
tags: 机器学习
keywords: model evaluation
description:
---

本文涉及以下内容
- SVM
- confusion matrix的实现
- 用pickle保存和加载模型

## SVM简介

SVM的优势是可以解决`小样本`、`非线性`、`高维模式识别`的问题  

SVM建立在`统计学习理论`中的`VC维理论`和`结构风险最小理论`的基础上，根据有限样本信息在模型的复杂性（即对特定训练样本的学习精度）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折中    
数据点是n维实空间的点，希望把这些点用一个n-1维的超平面分开。这类分类器叫做`线性分类器`  
有很多分类器符合这种要求。但是我们还希望找到最佳分割平面，也就是使得两个类的数据点间隔最大的那个平面。  

### 优点
- 通用性：能够各种函数集中构造函数
- 鲁棒性：不需要微调
- 有效性：解决实际问题最好的方法
- 计算简单，理论完善：基于VC推广理论框架
- 与传统统计理论相比，统计学习理论基本`不涉及概率测度的定义和大数定律`
- 建立了有限样本学习问题的统一框架
- 避免了神经网络的网络结构选择、过学习、欠学习以及局部最小值问题


## Python 实现


### 1. 生成数据

随机地生成数据

```py
import numpy as np
import pandas as pd
from scipy.stats import uniform
x1 = uniform.rvs(loc=0, scale=1, size=100)
x2 = uniform.rvs(loc=0, scale=2, size=100)
data = pd.DataFrame({'x1': x1, 'x2': x2})
data['y'] = (data['x1'] + 0.5 * data['x2'] < 1) * 1
```

### 2. 数据可视化
```py
import matplotlib.pyplot as plt
plt.plot(data[data.y == 1]['x1'], data[data.y == 1]['x2'], '.')
plt.plot(data[data.y == 0]['x1'], data[data.y == 0]['x2'], '.')
plt.show()
```

<img src='http://www.guofei.site/public/postimg/svm_1.png'>


### 3. 选取训练集和测试集


```py
from numpy.random import shuffle  # 引入随机函数
n=data.shape[0]
mac=np.arange(n)#掩码，用于随机打乱顺序
shuffle(mac)  # 随机打乱数据
data=data.loc[mac]
data_train = data.iloc[:int(0.8*n),:]  # 选取80%为训练数据
data_test = data.iloc[int(0.8*n):,:]  # 选取20%为测试数据

x_train = data_train.loc[:,['x1','x2']]
y_train = data_train.loc[:, 'y']#svm的y需要输入1darray
x_test = data_test.loc[:,['x1','x2']]
y_test = data_test.loc[:, ['y']]
```

这段代码不算太美丽，以后看看能不能改进


### 4. 模型计算

```py
from sklearn import svm
model = svm.SVC()
model.fit(x_train, y_train)
```

### 5. 混淆矩阵

```py
from sklearn import metrics

cm_train = metrics.confusion_matrix(y_train, model.predict(x_train))  # 训练样本的混淆矩阵
cm_test = metrics.confusion_matrix(y_test, model.predict(x_test))  # 测试样本的混淆矩阵
print(cm_train)
print(cm_test)
```

### 6. 模型保存


```py
import pickle
pickle.dump(model, open('svm.model', 'wb'))
# 以后可以通过下面语句重新加载模型：
# model = pickle.load(open('../tmp/svm.model', 'rb'))
```

下次加载后，也不需要sklearn这个包了  


## 一个多分类的案例

### 1. 随机生成数据并画图

```py
import numpy as np
import pandas as pd
from scipy.stats import uniform
import matplotlib.pyplot as plt

x1 = uniform.rvs(loc=0, scale=1, size=1000)
x2 = uniform.rvs(loc=0, scale=2, size=1000)
data = pd.DataFrame({'x1': x1, 'x2': x2})
data['y'] = 0
data.loc[data['x1'] + 0.5 * data['x2'] > 0.7, 'y'] = 1
data.loc[data['x1'] + 0.5 * data['x2'] > 1.3, 'y'] = 2
plt.plot(data[data.y == 0]['x1'], data[data.y == 0]['x2'], '.')
plt.plot(data[data.y == 1]['x1'], data[data.y == 1]['x2'], '.')
plt.plot(data[data.y == 2]['x1'], data[data.y == 2]['x2'], '.')
plt.show()
print(data['y'].value_counts())
```

<img src='http://www.guofei.site/public/postimg/svm_2.png'>

还有print的内容：
```py
1    520
2    266
0    214
```

显示这个的原因是，有可能有某个类数量很少，导致test或train中没有这个类。  
解决方法：
1. 从业务或数据角度去解决。  
2. 每个类分别取test和train



### 2. 画图，略过


### 3. 选取训练集和测试集

这里想保证每个类都有80%数据选入train，代码这样改：  

```py
from numpy.random import shuffle  # 引入随机函数
n=data.shape[0]
mac=np.arange(n)#掩码，用于随机打乱顺序
shuffle(mac)  # 随机打乱数据
data=data.loc[mac]

data_train=pd.DataFrame()
data_test=pd.DataFrame()
for i , t in data.groupby(data.loc[:,'y']):
    n_temp=t.shape[0]
    data_train=pd.concat([data_train,t.iloc[:int(0.8*n_temp)]])
    data_test=pd.concat([data_test,t.iloc[int(0.8*n_temp):]])
```

这里用了几个技巧，你可以想想自己能不能写出来

#### 4. 其他代码
没什么改动了
















参考文献：

[支持向量机通俗导论（理解SVM的三层境界）
](http://blog.csdn.net/v_july_v/article/details/7624837)
