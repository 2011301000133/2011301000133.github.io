## 决策树


决策树是一种强大的`有监督`数据挖掘技术，它能应用范围非常广，而且产生的模型`具有可解释性`，而且可以用来`筛选变量`。


决策树的特点：
- 每个节点两个走向
- 每个节点1个变量
- 变量可以重复使用



优点：  
- 易于理解和解释，人们都有能力理解决策树所表达的意义  
例如，收集专家的历史数据，用决策树可以总结出他的经验。  
例如，拿到别人的交易清单，可以模拟出这个交易员  
- 和其它模型相比，数据的预处理往往是不必要的。例如，不需要归一化
- 可以同时处理分类变量和连续变量。其它模型很多要求数据类型单一
- 白盒模型，可以轻松推出逻辑表达式
- 计算量少，大量数据可也以快速得出良好结果  

缺点：  
- 样本各类别数量不同时，结果更偏向于类别多的。
（除了朴素贝叶斯之外的大多数模型都存在这个问题）
- 过拟合
- 忽略自变量之间的相关性
